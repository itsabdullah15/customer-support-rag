RAG Chatbot for Customer Support
This project implements a Retrieval-Augmented Generation (RAG) chatbot trained on customer support documentation. It retrieves relevant information using FAISS and generates answers using the Groq language model (LLaMA-3.1-8B). It includes a Streamlit-based interface and is designed to only answer questions based on the provided context, returning "I don't know" for out-of-scope queries.

ğŸš€ Features

ğŸ” Document Retrieval: Uses FAISS to fetch top 3 most relevant documents from indexed embeddings.
ğŸ¤– Answer Generation: Uses Groq's LLaMA-3.1-8B model to generate contextual answers.
â“ Out-of-Scope Handling: Returns "I don't know" when the answer is not in the provided documents.
ğŸ–¥ï¸ User Interface: Streamlit UI with expandable document views for transparency.
ğŸ§± Modular Design: Separates UI (app.py) and RAG logic (rag_chain.py) for easy maintenance.


ğŸ“ Project Structure
CUSTOMER-SUPPORT-RAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ documents.json              # JSON file with document texts
â”‚   â”œâ”€â”€ faiss_index.index           # FAISS index for retrieval
â”‚   â”œâ”€â”€ ingest.ipynb                # Notebook for ingesting data
â”‚   â”œâ”€â”€ interface.py                # Streamlit app interface
â”‚   â””â”€â”€ rag_chain.py                # RAG logic and pipeline
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ angelone_quick_10_links_support_data.json
â”‚   â”œâ”€â”€ angelone_support_full_data.json
â”‚   â””â”€â”€ insurance_pdfs_text.json
â”‚
â”œâ”€â”€ Data Gathering/
â”‚   â”œâ”€â”€ Insurance PDFs/
â”‚   â”œâ”€â”€ angelone_quick_10_links_support_data.json
â”‚   â”œâ”€â”€ angelone_support_full_data.json
â”‚   â”œâ”€â”€ insurance_pdfs_text.json
â”‚   â”œâ”€â”€ insurance_pdfs_text1.json
â”‚   â””â”€â”€ data_gathering.ipynb
â”‚
â”œâ”€â”€ .env                            # Environment variables (GROQ_API_KEY)
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ requirements.txt                # Python dependencies



ğŸ› ï¸ Requirements
To install the required dependencies, run:
pip install -r requirements.txt

requirements.txt
langchain==0.1.10
openai==1.19.0
faiss-cpu==1.7.4
sentence-transformers==2.2.2
PyPDF2==3.0.1
pdfplumber==0.10.2
beautifulsoup4==4.12.3
requests==2.31.0
lxml==5.2.1
streamlit==1.33.0
tqdm==4.66.2
numpy==1.26.4
pandas==2.2.2
python-dotenv==1.0.1


ğŸ”‘ Environment Setup
Create a .env file in the root directory with your Groq API key:
GROQ_API_KEY=your_groq_api_key_here


ğŸš€ Running the Application

Ingest Data (if not already done):

Run the ingest.ipynb notebook to process documents and create the FAISS index (faiss_index.index) and documents.json.


Start the Streamlit App:
streamlit run app/interface.py


Interact with the Chatbot:

Open the provided local URL (e.g., http://localhost:8501) in your browser.
Ask questions related to the customer support documentation.
Expand the document sections to view retrieved context.




ğŸ“ Notes

The chatbot is designed to only answer based on the provided documents. If a question is out of scope, it will respond with "I don't know".
Ensure the FAISS index and documents.json are present in the app/ directory before running the app.
The data in the data/ and Data Gathering/ directories includes JSON files with customer support data and extracted text from insurance PDFs.


ğŸ› ï¸ Troubleshooting

Missing FAISS Index: Run ingest.ipynb to generate faiss_index.index and documents.json.
API Key Issues: Verify the GROQ_API_KEY in the .env file.
Dependency Errors: Ensure all packages in requirements.txt are installed correctly using the specified versions.


ğŸ“š References

LangChain Documentation
FAISS
Streamlit
Groq API

